{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my extended search function fromte text processing assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# test\n",
    "#%notify\n",
    "#import time\n",
    "#time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob, os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver. 2 - uses a list of regex terms. #### THIS IS BUGGED!!!\n",
    "\n",
    "### NOTE ###\n",
    "# - The code counts terms twice, if they are similar within the same pass. This means that drunk* and drun* count 1 and 2, because the loop counts drunk* again on the second iteration. THIS IS A PROBLEM WITH DRUNK* AND DRUNKARD!!!\n",
    "# -  \n",
    "\n",
    "def regex_search(folder_path , regList):\n",
    "    \"\"\"\n",
    "    Search a folder path for a given regex.\n",
    "\n",
    "    :folder_path: a string with the path to a dir with processed .txt files \n",
    "    :regList: a list of regular expressions as strings.\n",
    "    \"\"\"\n",
    "    resultsDict = defaultdict(lambda: defaultdict(dict)) #consider using regular dict for the inner layer, since you know which terms you are searching.\n",
    "\n",
    "\n",
    "    # file_names = [] \n",
    "\n",
    "    # compile any search term(s) given for searching.\n",
    "    #search_terms = re.compile('|'.join(regList)) # with word boundaries: re.compile(r'\\b(?:%s)\\b' % '|'.join(regList))\n",
    "    search_terms_re = [re.compile(reg) for reg in regList]\n",
    "\n",
    "\n",
    "    #loop through the folder with txt files.\n",
    "    for filepath in glob.iglob(folder_path + \"/*\"):  #for future reference, if you just want to iterate through a number of files, use os.listdir() and slice it [:20] for instance.\n",
    "        n_hits = 0\n",
    "        filename = os.path.basename(filepath)\n",
    "        #file_names.append(filename)\n",
    "        \n",
    "        #open the file\n",
    "        with open(filepath, \"r\") as infile:\n",
    "            content = infile.read()\n",
    "\n",
    "        #find the document length (total tokens)\n",
    "        resultsDict[filename]['text_length'] = len(re.findall(r'\\w+', content)) #consider using the token pattern from https://github.com/gearmonkey/tfidf-python/blob/master/tfidf.py : re.findall(r\"<a.*?/a>|<[^\\>]*>|[\\w'@#]+\")\n",
    "\n",
    "        #search for the terms in the file, given the list of regexes.\n",
    "        for term in search_terms_re:\n",
    "            if term.findall(content):\n",
    "                n_hits += 1\n",
    "           \n",
    "\n",
    "        # add the coutn of hits to the nested results dictionary \n",
    "            resultsDict[filename][term.pattern] = n_hits\n",
    "\n",
    "\n",
    "    #export to df\n",
    "    resultsDF = pd.DataFrame.from_dict(resultsDict, orient='index')\n",
    "    # (re)name the index column\n",
    "    #resultsDF = resultsDF.rename_axis('file_id')\n",
    "\n",
    "    return resultsDF\n",
    "\n",
    "#print(output)\n",
    "#print(list(results.items())[:10])\n",
    "\n",
    "\n",
    "#### for this code I used solutions from:\n",
    "# https://stackoverflow.com/questions/6750240/how-to-do-re-compile-with-a-list-in-python\n",
    "# https://howchoo.com/g/yjjknjdinmq/nested-defaultdict-python\n",
    "# https://stackoverflow.com/questions/19851005/rename-pandas-dataframe-index \n",
    "# https://www.geeksforgeeks.org/python-program-to-count-words-in-a-sentence/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver. 3 - debugging the count of regexes.\n",
    "\n",
    "### NOTE ###\n",
    "# - The code counts terms twice, if they are similar within the same pass. This means that drunk* and drun* count 1 and 2, because the loop counts drunk* again on the second iteration. THIS IS A PROBLEM WITH DRUNK* AND DRUNKARD!!!\n",
    "# -  \n",
    "\n",
    "def regex_search(folder_path , regList):\n",
    "    \"\"\"\n",
    "    Search a folder path for a given regex.\n",
    "\n",
    "    :folder_path: a string with the path to a dir with processed .txt files \n",
    "    :regList: a list of regular expressions as strings.\n",
    "    \"\"\"\n",
    "    resultsDict = defaultdict(lambda: defaultdict(dict)) #consider using regular dict for the inner layer, since you know which terms you are searching.\n",
    "\n",
    "\n",
    "    # file_names = [] \n",
    "\n",
    "    # compile any search term(s) given for searching.\n",
    "    #search_terms = re.compile('|'.join(regList)) # with word boundaries: re.compile(r'\\b(?:%s)\\b' % '|'.join(regList))\n",
    "    search_terms_re = [re.compile(reg) for reg in regList]\n",
    "\n",
    "        \n",
    "    #loop through the folder with txt files.\n",
    "    \n",
    "    for filepath in tqdm(list(glob.iglob(folder_path + \"/*\"))):  #consider using os.listdir() for a subset of files\n",
    "        filename = os.path.basename(filepath)\n",
    "\n",
    "        #open the file\n",
    "        with open(filepath, \"r\") as infile:\n",
    "            content = infile.read()\n",
    "\n",
    "        #find the document length (total tokens)\n",
    "        resultsDict[filename]['text_length'] = len(re.findall(r'\\w+', content)) #consider using the token pattern from https://github.com/gearmonkey/tfidf-python/blob/master/tfidf.py : re.findall(r\"<a.*?/a>|<[^\\>]*>|[\\w'@#]+\")\n",
    "\n",
    "        #search for the terms in the file, given the list of regexes.\n",
    "        for term in search_terms_re:\n",
    "            n_hits = 0\n",
    "            for match in re.finditer(term, content):\n",
    "                #print(term, match)\n",
    "                n_hits += 1\n",
    "                #print(n_hits)\n",
    "\n",
    "        # add the count of hits to the nested results dictionary with readable versions of the terms. \n",
    "                resultsDict[filename][re.sub(r'\\W+|w', '', str(term.pattern))] = n_hits \n",
    "\n",
    "\n",
    "\n",
    "    #export to df\n",
    "    resultsDF = pd.DataFrame.from_dict(resultsDict, orient='index').fillna(0)\n",
    "    # (re)name the index column\n",
    "    #resultsDF = resultsDF.rename_axis('file_id')\n",
    "    \n",
    "    \n",
    "    return resultsDF\n",
    "\n",
    "#print(output)\n",
    "#print(list(results.items())[:10])\n",
    "\n",
    "\n",
    "#### for this code I used solutions from:\n",
    "# https://stackoverflow.com/questions/6750240/how-to-do-re-compile-with-a-list-in-python\n",
    "# https://howchoo.com/g/yjjknjdinmq/nested-defaultdict-python\n",
    "# https://stackoverflow.com/questions/19851005/rename-pandas-dataframe-index \n",
    "# https://www.geeksforgeeks.org/python-program-to-count-words-in-a-sentence/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchQuery = [\n",
    "                \"drunk\\w*\",\n",
    "                \"intoxicat\\-?\\w*\",\n",
    "                \"temperance\",\n",
    "                \"beer\\-?\\w*\",\n",
    "                \"liquor\",\n",
    "                \"alcohol\\-?\\w*\",\n",
    "                \"brandy\",\n",
    "                \"booz\\-?\\w*\",\n",
    "                \"drunkard\",\n",
    "                \"by\\-drink\\w*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 136497/136497 [12:12<00:00, 186.26it/s]\n",
      "UsageError: Line magic function `%notify` not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#function call\n",
    "\n",
    "output = regex_search(\"C:/TEMPORARY/18\" , searchQuery)\n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inspect the dataframe\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output to a human friendly files\n",
    "\n",
    "output.to_csv('results.tsv', sep=\"\\t\", index_label='file_id')\n",
    "output.to_excel('results.xlsx', index_label='file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the output of the last run, drop the index column.\n",
    "df_in = pd.read_csv('results.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_length</th>\n",
       "      <th>drunk</th>\n",
       "      <th>intoxicat</th>\n",
       "      <th>liquor</th>\n",
       "      <th>beer</th>\n",
       "      <th>brandy</th>\n",
       "      <th>temperance</th>\n",
       "      <th>drunkard</th>\n",
       "      <th>booz</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>terms_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1800-01-15_f18000115-1-person44.txt</th>\n",
       "      <td>249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800-01-15_s18000115-1-person834.txt</th>\n",
       "      <td>295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800-01-15_t18000115-1-verdict5.txt</th>\n",
       "      <td>1660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800-01-15_t18000115-10-verdict52.txt</th>\n",
       "      <td>3373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800-01-15_t18000115-11-punish57.txt</th>\n",
       "      <td>415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899-12-11_t18991211-86-punishment-44.txt</th>\n",
       "      <td>1453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899-12-11_t18991211-87-punishment-45.txt</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899-12-11_t18991211-name-7.txt</th>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899-12-11_t18991211-name-98.txt</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.tsv</th>\n",
       "      <td>2221082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136497 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_length  drunk  intoxicat  \\\n",
       "file_id                                                                    \n",
       "1800-01-15_f18000115-1-person44.txt                249    0.0        0.0   \n",
       "1800-01-15_s18000115-1-person834.txt               295    0.0        0.0   \n",
       "1800-01-15_t18000115-1-verdict5.txt               1660    3.0        1.0   \n",
       "1800-01-15_t18000115-10-verdict52.txt             3373    0.0        0.0   \n",
       "1800-01-15_t18000115-11-punish57.txt               415    0.0        0.0   \n",
       "...                                                ...    ...        ...   \n",
       "1899-12-11_t18991211-86-punishment-44.txt         1453    0.0        0.0   \n",
       "1899-12-11_t18991211-87-punishment-45.txt           41    0.0        0.0   \n",
       "1899-12-11_t18991211-name-7.txt                    309    0.0        0.0   \n",
       "1899-12-11_t18991211-name-98.txt                    21    0.0        0.0   \n",
       "meta.tsv                                       2221082    0.0        0.0   \n",
       "\n",
       "                                           liquor  beer  brandy  temperance  \\\n",
       "file_id                                                                       \n",
       "1800-01-15_f18000115-1-person44.txt           0.0   0.0     0.0         0.0   \n",
       "1800-01-15_s18000115-1-person834.txt          0.0   0.0     0.0         0.0   \n",
       "1800-01-15_t18000115-1-verdict5.txt           2.0   0.0     0.0         0.0   \n",
       "1800-01-15_t18000115-10-verdict52.txt         1.0   0.0     0.0         0.0   \n",
       "1800-01-15_t18000115-11-punish57.txt          0.0   4.0     0.0         0.0   \n",
       "...                                           ...   ...     ...         ...   \n",
       "1899-12-11_t18991211-86-punishment-44.txt     0.0   0.0     0.0         0.0   \n",
       "1899-12-11_t18991211-87-punishment-45.txt     0.0   0.0     0.0         0.0   \n",
       "1899-12-11_t18991211-name-7.txt               0.0   0.0     0.0         0.0   \n",
       "1899-12-11_t18991211-name-98.txt              0.0   0.0     0.0         0.0   \n",
       "meta.tsv                                      0.0   0.0     0.0         0.0   \n",
       "\n",
       "                                           drunkard  booz  alcohol  terms_sum  \n",
       "file_id                                                                        \n",
       "1800-01-15_f18000115-1-person44.txt             0.0   0.0      0.0        0.0  \n",
       "1800-01-15_s18000115-1-person834.txt            0.0   0.0      0.0        0.0  \n",
       "1800-01-15_t18000115-1-verdict5.txt             0.0   0.0      0.0        6.0  \n",
       "1800-01-15_t18000115-10-verdict52.txt           0.0   0.0      0.0        1.0  \n",
       "1800-01-15_t18000115-11-punish57.txt            0.0   0.0      0.0        4.0  \n",
       "...                                             ...   ...      ...        ...  \n",
       "1899-12-11_t18991211-86-punishment-44.txt       0.0   0.0      0.0        0.0  \n",
       "1899-12-11_t18991211-87-punishment-45.txt       0.0   0.0      0.0        0.0  \n",
       "1899-12-11_t18991211-name-7.txt                 0.0   0.0      0.0        0.0  \n",
       "1899-12-11_t18991211-name-98.txt                0.0   0.0      0.0        0.0  \n",
       "meta.tsv                                        0.0   0.0      0.0        0.0  \n",
       "\n",
       "[136497 rows x 11 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add all values for the term columns\n",
    "df_in['terms_sum'] = df_in.iloc[:, 1:].sum(axis=1)  # https://stackoverflow.com/questions/48923460/how-do-i-sum-a-column-range-in-python\n",
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'drunk*'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drunk*'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-1e9cbd6c1ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tf = df_in[['text_length' , 'drunk*']].sum(axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drunk*'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drunk*'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# consider writing a function for each variable here and using .apply to insert the resulting computations in new columns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drunk*'"
     ]
    }
   ],
   "source": [
    "# tf = df_in[['text_length' , 'drunk*']].sum(axis=1)\n",
    "tf = df_in.loc[df_in['drunk*']>=1] = df_in['drunk*']/df_in['text_length']\n",
    "print(tf)\n",
    "\n",
    "# consider writing a function for each variable here and using .apply to insert the resulting computations in new columns.\n",
    "# otherwise, load it back into another container (dict of dicts and compute things from there before moving back to dataframe)\n",
    "\n",
    "#idf = len(df_in['file_id'] / column_values >=1)\n",
    "#df_in['tf_idf'] = tf*idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
